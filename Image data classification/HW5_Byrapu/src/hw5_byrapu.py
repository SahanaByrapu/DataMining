# -*- coding: utf-8 -*-
"""HW5_Byrapu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15jfyElk3lf4g9vC1PcqJeV5tW0XkSflG
"""

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,accuracy_score
from sklearn.cluster import KMeans
from nltk.tokenize import sent_tokenize, word_tokenize
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist
import gensim
import seaborn as sns
from gensim.models import Word2Vec
import nltk
nltk.download('punkt')
import warnings
warnings.filterwarnings(action = 'ignore')

PART 1- IRIS DATA SET

Testdata_df = pd.read_csv("/content/test_data.csv",names=["sepal_length", "sepal_width","petal_length","petal_width"],sep=" ",header=None)

Testdata_df

def kmeans1(X, k):
  diff = 1
  count=0
  #initialize the centroids with random points
  cluster = np.zeros(X.shape[0])
  centroids = Testdata_df.sample(n=k).values
  while diff:
     # for each observation
     distances = cdist(X, centroids ,'cosine')
     cluster = np.array([np.argmin(i) for i in distances])
     new_centroids = pd.DataFrame(X).groupby(by=cluster).mean().values
      # if centroids are same then leave
     if np.count_nonzero(centroids-new_centroids) == 0:
        diff = 0
     else:
        centroids = new_centroids
  count=count+1
  print(count)
  return centroids, cluster

k = 3
centroids, cluster = kmeans1(Testdata_df, k)
print(cluster)

"""writing the predicted data of k_means model into output file """
with open("pred_test_part1_new1.dat", "w") as a_file:
    for i in range(len(cluster)):
        a_file.write(str(int(float(cluster[i]))))
        a_file.write('\n')

def SSE(X, centroids, cluster):
  sum = 0
  for i, val in enumerate(X):
    sum += (centroids[int(cluster[i]), 0]-val[0])**2 +(centroids[int(cluster[i]), 1]-val[1])**2
  return sum

#sum of squared errors (SSE)
cost_list = []
X=Testdata_df.values
for k in range(1, 21):
     centroids, cluster = kmeans1(X, k)
     #print(centroids, cluster,type(centroids),type(cluster),len(centroids))
    # WCSS (Within cluster sum of square)
     cost = SSE(X, centroids, cluster)
     cost_list.append(cost)

sns.lineplot(x=range(1,21), y=cost_list, marker='o')
plt.xlabel('k')
plt.ylabel('WCSS')
plt.show()

PART 2- IMAGE DATA SET

Testdata_img_df = pd.read_csv("/content/test_img_data.csv",sep=",",header=None)
Testdata_img_df=Testdata_img_df.dropna(axis=1,how='any')
Testdata_img_df

# Commented out IPython magic to ensure Python compatibility.
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
# %config InlineBackend.figure_format='retina'

# Standardize the data to have a mean of ~0 and a variance of 1
X_std = StandardScaler().fit_transform(Testdata_img_df)
# Create a PCA instance: pca
pca = PCA(n_components=72)
pca_result = pca.fit_transform(X_std)

#time_start = time.time()
tsne = TSNE(n_components=3, verbose=1, perplexity=8, n_iter=250)
tsne_results = tsne.fit_transform(pca_result)

X=pd.DataFrame(tsne_results)
X.shape

def kmeans2(X, k):
  diff = 1
  cluster = np.zeros(X.shape[0])
  centroids= X.sample(n=k).values
  while diff:
        distances = cdist(X, centroids ,'cosine')
        #print(distances)
        # store closest centroid
        cluster = np.array([np.argmin(i) for i in distances])
        new_centroids = pd.DataFrame(X).groupby(by=cluster).mean().values
        #print("centroids",centroids,centroids.shape,"new_centroids",new_centroids,new_centroids.shape)
         # if centroids are same then leave
        if np.count_nonzero(centroids-new_centroids) == 0:
          diff = 0
        else:
          centroids = new_centroids
  return centroids, cluster

k=10
Y=Testdata_img_df
centroids1, cluster1=kmeans2(Y, k)

print(cluster1)

"""writing the predicted data of k_means model into output file """
with open("pred_test_part2_new1.dat", "w") as a_file:
    for i in range(len(cluster1)):
        a_file.write(str(int(float(cluster1[i]))))
        a_file.write('\n')

k = 10
centroids, cluster = kmeans2(X, k)

"""writing the predicted data of k_means model into output file """
with open("pred_test_part2_new1.dat", "w") as a_file:
    for i in range(len(cluster)):
        a_file.write(str(int(float(cluster[i]))))
        a_file.write('\n')

def calculate_cost2(X, centroids, cluster):
  sum = 0
  for i, val in enumerate(X):
    #print(int(cluster[i]),"val=",val)
    sum += (centroids[int(cluster[i]), 0]-val[0])**2 +(centroids[int(cluster[i]), 1]-val[1])**2 + (centroids[int(cluster[i]), 2]-val[2])**2
  return sum

cost_list = []
X=pd.DataFrame(tsne_results)

for k in range(1, 21):
     centroids, cluster = kmeans2(X, k)
    # WCSS (Within cluster sum of square)
     X1=pd.DataFrame(tsne_results).values
     cost = calculate_cost2(X1, centroids, cluster)
     cost_list.append(cost)

sns.lineplot(x=range(1,21), y=cost_list, marker='o')
plt.xlabel('k')
plt.ylabel('WCSS')
plt.show()

"""writing the predicted data of k_means model into output file """
with open("pred_test_part2_new.dat", "w") as a_file:
    for i in range(len(cluster)):
        a_file.write(str(int(float(cluster[i]))))
        a_file.write('\n')